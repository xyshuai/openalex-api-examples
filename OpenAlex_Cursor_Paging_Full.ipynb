{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzExzCyOI7C5vBCiHTzmEp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xyshuai/openalex-api-demo/blob/main/OpenAlex_Cursor_Paging_Full.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKM3NH2yaoE5"
      },
      "outputs": [],
      "source": [
        "import os, csv, time, requests\n",
        "\n",
        "# ---------------- Google Drive Setup ----------------\n",
        "USE_DRIVE = False\n",
        "try:\n",
        "    from google.colab import drive, files  # type: ignore\n",
        "    try:\n",
        "        drive.mount('/content/drive', force_remount=True)\n",
        "        USE_DRIVE = True\n",
        "        OUT_DIR = \"/content/drive/MyDrive/OpenAlex\"\n",
        "        print(\"‚úÖ Google Drive mounted. Saving to:\", OUT_DIR)\n",
        "    except Exception as e:\n",
        "        print(\"‚ö†Ô∏è Failed to mount Google Drive. Falling back to /content. Error:\", e)\n",
        "        OUT_DIR = \"/content\"\n",
        "except Exception:\n",
        "    # Not running in Colab; save to the current working directory\n",
        "    OUT_DIR = \".\"\n",
        "    print(\"‚ÑπÔ∏è Not running in Colab. Saving to the current directory.\")\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# ---------------- Config ----------------\n",
        "# Base endpoint only (DO NOT paste UI-generated URLs with filters)\n",
        "BASE_URL = \"https://api.openalex.org/works\"\n",
        "MAILTO = \"your.email@domain.com\"  # TODO: Replace with your email\n",
        "\n",
        "# Years to harvest (This is an demo example, you may change the range based on your needs)\n",
        "YEARS = list(range(2023, 2025))   # Example: 2023‚Äì2024\n",
        "PER_PAGE = 200                    # Cursor pagination max = 200\n",
        "MAX_PAGES = 5                 # None ‚Üí full harvest; set to small int (e.g., 5) for testing\n",
        "SLEEP_SEC = 1.0                   # Delay between pages; increase if rate-limited\n",
        "\n",
        "# Base filter\n",
        "# For \"authors with country MY\", use authorships.countries\n",
        "# For \"affiliated institutions in MY\", replace with institutions.country_code:my\n",
        "BASE_FILTER = \"open_access.is_oa:true,authorships.countries:countries/my,type:types/article|types/review\"\n",
        "SORT = \"cited_by_count:desc\"\n",
        "\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:122.0) Gecko/20100101 Firefox/122.0\",\n",
        "    \"Accept\": \"application/json\",\n",
        "    \"From\": MAILTO,\n",
        "}\n",
        "\n",
        "# Select only top-level fields allowed by OpenAlex\n",
        "SELECT_FIELDS = [\n",
        "    \"id\", \"doi\", \"title\", \"display_name\", \"type\", \"language\",\n",
        "    \"publication_year\", \"cited_by_count\",\n",
        "    \"primary_location\", \"sources\",\n",
        "    \"open_access\", \"best_oa_location\",\n",
        "    \"authorships\", \"institutions\",\n",
        "    \"concepts\", \"primary_topic\", \"topics\",\n",
        "    \"fwci\", \"citation_normalized_percentile\",\n",
        "    \"apc_list\", \"sustainable_development_goals\"\n",
        "]\n",
        "SELECT_PARAM = \",\".join(SELECT_FIELDS)\n",
        "\n",
        "# Column headers for CSV export\n",
        "CSV_HEADERS = [\n",
        "    \"openalex_id\", \"doi\", \"title\", \"year\", \"type\", \"language\",\n",
        "    \"cited_by_count\", \"journal\", \"issn_l\",\n",
        "    \"is_oa\", \"oa_status\", \"oa_url\", \"license\", \"version\",\n",
        "    \"first_author\", \"authors\", \"authors_affiliations\",\n",
        "    \"corresponding_authors\", \"corresponding_author_country_codes\",\n",
        "    \"primary_topic_id\", \"primary_topic_name\",\n",
        "    \"primary_topic_domain\", \"primary_topic_field\", \"primary_topic_subfield\",\n",
        "    \"topics_top5\",\n",
        "    \"apc_list_values\",\n",
        "    \"fwci\", \"citation_percentile\", \"citation_top_1pct\", \"citation_top_10pct\",\n",
        "    \"sdg_labels\",\n",
        "]\n",
        "\n",
        "# ---------------- Helper Functions ----------------\n",
        "def flatten_authors(authorships):\n",
        "    if not authorships: return \"\"\n",
        "    names = []\n",
        "    for a in authorships:\n",
        "        nm = (a.get(\"author\") or {}).get(\"display_name\")\n",
        "        if nm: names.append(nm)\n",
        "    return \"; \".join(names)\n",
        "\n",
        "def flatten_authors_affils(authorships):\n",
        "    \"\"\"\n",
        "    Format authors as:\n",
        "      Author A (Affil1;Affil2); Author B (Affil3)\n",
        "    \"\"\"\n",
        "    if not authorships: return \"\"\n",
        "    parts = []\n",
        "    for a in authorships:\n",
        "        nm = (a.get(\"author\") or {}).get(\"display_name\") or \"\"\n",
        "        affs = []\n",
        "        for inst in (a.get(\"institutions\") or []):\n",
        "            dn = inst.get(\"display_name\") or \"\"\n",
        "            if dn: affs.append(dn)\n",
        "        if nm:\n",
        "            parts.append(nm if not affs else f\"{nm} ({';'.join(affs)})\")\n",
        "    return \"; \".join(parts)\n",
        "\n",
        "def corresponding_authors_list(authorships):\n",
        "    \"\"\"Extract corresponding authors.\"\"\"\n",
        "    if not authorships: return \"\"\n",
        "    names = []\n",
        "    for a in authorships:\n",
        "        if a.get(\"is_corresponding\"):\n",
        "            nm = (a.get(\"author\") or {}).get(\"display_name\")\n",
        "            if nm: names.append(nm)\n",
        "    return \"; \".join(names)\n",
        "\n",
        "def corresponding_author_country_codes(authorships):\n",
        "    \"\"\"\n",
        "    Collect country codes for corresponding author(s):\n",
        "    - For each authorship with is_corresponding=True:\n",
        "      * authorships[i].countries[]\n",
        "      * authorships[i].institutions[].country_code\n",
        "    \"\"\"\n",
        "    if not authorships:\n",
        "        return \"\"\n",
        "    s = set()\n",
        "    for a in authorships:\n",
        "        if not a.get(\"is_corresponding\"):\n",
        "            continue\n",
        "        for c in (a.get(\"countries\") or []):\n",
        "            if c:\n",
        "                s.add(c)\n",
        "        for inst in (a.get(\"institutions\") or []):\n",
        "            cc = inst.get(\"country_code\")\n",
        "            if cc:\n",
        "                s.add(cc)\n",
        "    return \";\".join(sorted(s)) if s else \"\"\n",
        "\n",
        "def pick_venue_from_primary_or_sources(w):\n",
        "    \"\"\"Extract journal / ISSN-L from primary_location or sources[] as fallback.\"\"\"\n",
        "    journal, issn_l = \"\", \"\"\n",
        "    pl = w.get(\"primary_location\") or {}\n",
        "    src = pl.get(\"source\") or {}\n",
        "    if isinstance(src, dict):\n",
        "        journal = src.get(\"display_name\", \"\") or journal\n",
        "        issn_l = src.get(\"issn_l\", \"\") or issn_l\n",
        "\n",
        "    if not journal or not issn_l:\n",
        "        for s in (w.get(\"sources\") or []):\n",
        "            if isinstance(s, dict) and s.get(\"type\") == \"journal\" and s.get(\"display_name\"):\n",
        "                journal = journal or s.get(\"display_name\", \"\")\n",
        "                issn_l = issn_l or s.get(\"issn_l\", \"\")\n",
        "                break\n",
        "        if not journal or not issn_l:\n",
        "            for s in (w.get(\"sources\") or []):\n",
        "                if isinstance(s, dict) and s.get(\"display_name\"):\n",
        "                    journal = journal or s.get(\"display_name\", \"\")\n",
        "                    issn_l = issn_l or s.get(\"issn_l\", \"\")\n",
        "                    break\n",
        "    return journal, issn_l\n",
        "\n",
        "def topics_top5_str(w):\n",
        "    \"\"\"Return top 5 non-primary topics sorted by score.\"\"\"\n",
        "    primary = w.get(\"primary_topic\") or {}\n",
        "    primary_id = primary.get(\"id\", \"\")\n",
        "    topics = w.get(\"topics\") or []\n",
        "    if not isinstance(topics, list): return \"\"\n",
        "    others = [t for t in topics if isinstance(t, dict) and t.get(\"id\") != primary_id]\n",
        "    others_sorted = sorted(others, key=lambda t: t.get(\"score\", 0) or 0, reverse=True)[:5]\n",
        "    out = []\n",
        "    for t in others_sorted:\n",
        "        name = t.get(\"display_name\", \"\")\n",
        "        sc = t.get(\"score\", None)\n",
        "        if name:\n",
        "            out.append(f\"{name} (score={sc:.2f})\" if isinstance(sc, (int, float)) else name)\n",
        "    return \"; \".join(out)\n",
        "\n",
        "def percentile_fields(w):\n",
        "    \"\"\"Handle citation_normalized_percentile fields.\"\"\"\n",
        "    cnp = w.get(\"citation_normalized_percentile\") or {}\n",
        "    val = cnp.get(\"value\", None)\n",
        "    pct = f\"{val:.6f}\" if isinstance(val, (int, float)) else \"\"\n",
        "    top1 = cnp.get(\"is_in_top_1_percent\")\n",
        "    top10 = cnp.get(\"is_in_top_10_percent\")\n",
        "    return (\n",
        "        pct,\n",
        "        \"Yes\" if top1 else (\"No\" if top1 is not None else \"\"),\n",
        "        \"Yes\" if top10 else (\"No\" if top10 is not None else \"\")\n",
        "    )\n",
        "\n",
        "def apc_list_values_str(work):\n",
        "    \"\"\"Normalize apc_list into readable string.\"\"\"\n",
        "    apc = work.get(\"apc_list\", None)\n",
        "    items = []\n",
        "    def norm_one(x):\n",
        "        if isinstance(x, dict):\n",
        "            val = x.get(\"value\", None); cur = x.get(\"currency\", \"\")\n",
        "            if val is not None and cur: return f\"{val} {cur}\"\n",
        "            if val is not None: return str(val)\n",
        "            if cur: return cur\n",
        "            return \"\"\n",
        "        if isinstance(x, (int, float)): return str(x)\n",
        "        if isinstance(x, str): return x.strip()\n",
        "        return \"\"\n",
        "    if isinstance(apc, list):\n",
        "        for it in apc:\n",
        "            s = norm_one(it);  s and items.append(s)\n",
        "    elif isinstance(apc, dict):\n",
        "        s = norm_one(apc);   s and items.append(s)\n",
        "    elif apc is not None:\n",
        "        s = norm_one(apc);   s and items.append(s)\n",
        "    return \"; \".join(items)\n",
        "\n",
        "def parse_sdg_labels(work):\n",
        "    \"\"\"\n",
        "    Extract SDG information from 'sustainable_development_goals'.\n",
        "    Returns a string like: 'SDG 3: Good health and well-being (0.95); SDG 4: Quality education (0.87)'\n",
        "    \"\"\"\n",
        "    sdg_field = work.get(\"sustainable_development_goals\")\n",
        "\n",
        "    if not sdg_field:\n",
        "        return \"\"\n",
        "\n",
        "    labels = []\n",
        "\n",
        "    # OpenAlex returns a list with id, display_name, score\n",
        "    if isinstance(sdg_field, list):\n",
        "        for item in sdg_field:\n",
        "            if isinstance(item, dict):\n",
        "                # Extract SDG number from id URL (e.g., \"https://metadata.un.org/sdg/3\" -> \"3\")\n",
        "                sdg_id = item.get(\"id\", \"\")\n",
        "                sdg_number = \"\"\n",
        "                if sdg_id:\n",
        "                    try:\n",
        "                        sdg_number = sdg_id.rstrip('/').split('/')[-1]\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                name = item.get(\"display_name\", \"\")\n",
        "                score = item.get(\"score\")\n",
        "\n",
        "                if name:\n",
        "                    # Combine into full format: SDG 3: Good health and well-being (0.95)\n",
        "                    if sdg_number:\n",
        "                        full_label = f\"SDG {sdg_number}: {name}\"\n",
        "                    else:\n",
        "                        full_label = name\n",
        "\n",
        "                    if score is not None:\n",
        "                        labels.append(f\"{full_label} ({score:.2f})\")\n",
        "                    else:\n",
        "                        labels.append(full_label)\n",
        "        if labels:\n",
        "            return \"; \".join(labels)\n",
        "\n",
        "    # If not list format, try other handling\n",
        "    elif isinstance(sdg_field, dict):\n",
        "        sdg_id = sdg_field.get(\"id\", \"\")\n",
        "        sdg_number = \"\"\n",
        "        if sdg_id:\n",
        "            try:\n",
        "                sdg_number = sdg_id.rstrip('/').split('/')[-1]\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        name = sdg_field.get(\"display_name\", \"\")\n",
        "        score = sdg_field.get(\"score\")\n",
        "\n",
        "        if name:\n",
        "            if sdg_number:\n",
        "                full_label = f\"SDG {sdg_number}: {name}\"\n",
        "            else:\n",
        "                full_label = name\n",
        "\n",
        "            if score is not None:\n",
        "                return f\"{full_label} ({score:.2f})\"\n",
        "            return full_label\n",
        "\n",
        "    elif isinstance(sdg_field, str):\n",
        "        return sdg_field.strip()\n",
        "\n",
        "    return \"\"\n",
        "\n",
        "# ---------------- Run (multi-year full harvest) ----------------\n",
        "print(f\"üìÅ Output directory: {OUT_DIR}\")\n",
        "print(f\"üìÖ Years to process: {YEARS}\")\n",
        "print(f\"üìä MAX_PAGES setting: {MAX_PAGES if MAX_PAGES else 'Full harvest'}\")\n",
        "print()\n",
        "\n",
        "for YEAR in YEARS:\n",
        "    cursor = \"*\"\n",
        "    total = 0\n",
        "    pages_done = 0\n",
        "\n",
        "    FILTER = f\"{BASE_FILTER},publication_year:{YEAR}\"\n",
        "    CSV_PATH = os.path.join(OUT_DIR, f\"openalex_{YEAR}.csv\")\n",
        "    print(f\"\\n‚ñ∂Ô∏è Starting year {YEAR}, output: {CSV_PATH}\")\n",
        "\n",
        "    with open(CSV_PATH, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(CSV_HEADERS)\n",
        "\n",
        "        while True:\n",
        "            # Build URL manually to avoid URL-encoded slashes (%2F ‚Üí can trigger 403)\n",
        "            query = (\n",
        "                f\"filter={FILTER}\"\n",
        "                f\"&sort={SORT}\"\n",
        "                f\"&per_page={PER_PAGE}\"\n",
        "                f\"&cursor={cursor}\"\n",
        "                f\"&select={SELECT_PARAM}\"\n",
        "                f\"&mailto={MAILTO}\"\n",
        "            )\n",
        "            url = f\"{BASE_URL}?{query}\"\n",
        "            if total == 0:\n",
        "                print(\"üõ∞Ô∏è Request:\", url[:150] + \"...\")\n",
        "\n",
        "            r = requests.get(url, headers=HEADERS, timeout=120)\n",
        "            if r.status_code != 200:\n",
        "                print(f\"üö´ HTTP {r.status_code}: {r.text[:300]}\")\n",
        "                time.sleep(SLEEP_SEC * 2)\n",
        "                continue\n",
        "\n",
        "            data = r.json()\n",
        "            if pages_done == 0:\n",
        "                meta_count = (data.get(\"meta\") or {}).get(\"count\")\n",
        "                print(f\"üìä Year {YEAR} official meta.count = {meta_count}\")\n",
        "\n",
        "            results = data.get(\"results\", [])\n",
        "            next_cursor = data.get(\"meta\", {}).get(\"next_cursor\")\n",
        "\n",
        "            if not results:\n",
        "                print(f\"‚úÖ Year {YEAR}: no more results.\")\n",
        "                break\n",
        "\n",
        "            for w in results:\n",
        "                # Safety check ‚Äî write only records with matching year\n",
        "                year = w.get(\"publication_year\", \"\")\n",
        "                if str(year) != str(YEAR):\n",
        "                    continue\n",
        "\n",
        "                doi = w.get(\"doi\", \"\")\n",
        "                title = w.get(\"display_name\") or w.get(\"title\", \"\")\n",
        "                wtype = w.get(\"type\", \"\")\n",
        "                lang = w.get(\"language\", \"\")\n",
        "                cited = w.get(\"cited_by_count\", 0)\n",
        "\n",
        "                journal, issn_l = pick_venue_from_primary_or_sources(w)\n",
        "\n",
        "                oa = w.get(\"open_access\") or {}\n",
        "                is_oa = \"Yes\" if oa.get(\"is_oa\") else \"No\"\n",
        "                oa_status = oa.get(\"oa_status\", \"\")\n",
        "                oa_url = oa.get(\"oa_url\", \"\")\n",
        "\n",
        "                boa = w.get(\"best_oa_location\") or {}\n",
        "                license_ = boa.get(\"license\", \"\")\n",
        "                version = boa.get(\"version\", \"\")\n",
        "\n",
        "                authorships = w.get(\"authorships\", [])\n",
        "                first_author = authorships[0].get(\"author\", {}).get(\"display_name\") if authorships else \"\"\n",
        "                authors = flatten_authors(authorships)\n",
        "                authors_affils = flatten_authors_affils(authorships)\n",
        "                corr_authors = corresponding_authors_list(authorships)\n",
        "                corr_author_cc = corresponding_author_country_codes(authorships)\n",
        "\n",
        "                primary = w.get(\"primary_topic\") or {}\n",
        "                primary_topic_id = primary.get(\"id\", \"\")\n",
        "                primary_topic_name = primary.get(\"display_name\", \"\")\n",
        "                primary_topic_domain = (primary.get(\"domain\") or {}).get(\"display_name\", \"\")\n",
        "                primary_topic_field = (primary.get(\"field\") or {}).get(\"display_name\", \"\")\n",
        "                primary_topic_subfield = (primary.get(\"subfield\") or {}).get(\"display_name\", \"\")\n",
        "\n",
        "                top5 = topics_top5_str(w)\n",
        "                apc_values = apc_list_values_str(w)\n",
        "                fwci = w.get(\"fwci\", \"\")\n",
        "                citation_percentile, top1, top10 = percentile_fields(w)\n",
        "                sdg_labels = parse_sdg_labels(w)\n",
        "\n",
        "                writer.writerow([\n",
        "                    w.get(\"id\", \"\"), doi, title, year, wtype, lang,\n",
        "                    cited, journal, issn_l,\n",
        "                    is_oa, oa_status, oa_url, license_, version,\n",
        "                    first_author, authors, authors_affils,\n",
        "                    corr_authors, corr_author_cc,\n",
        "                    primary_topic_id, primary_topic_name,\n",
        "                    primary_topic_domain, primary_topic_field, primary_topic_subfield,\n",
        "                    top5,\n",
        "                    apc_values,\n",
        "                    fwci, citation_percentile, top1, top10,\n",
        "                    sdg_labels\n",
        "                ])\n",
        "                total += 1\n",
        "\n",
        "            pages_done += 1\n",
        "            print(f\"üì¶ Year {YEAR}, page {pages_done}: {len(results)} records, total {total}\")\n",
        "\n",
        "            cursor = next_cursor\n",
        "            if not cursor:\n",
        "                print(f\"‚úÖ Finished {YEAR}, total {total} records.\")\n",
        "                break\n",
        "\n",
        "            if (MAX_PAGES is not None) and (pages_done >= MAX_PAGES):\n",
        "                print(f\"‚èπÔ∏è Year {YEAR} reached MAX_PAGES={MAX_PAGES}, stopping early (test mode).\")\n",
        "                break\n",
        "\n",
        "            time.sleep(SLEEP_SEC)\n",
        "\n",
        "print(\"\\nüéâ All years processed.\")\n",
        "print(f\"üìÅ Files saved to: {OUT_DIR}\")\n",
        "\n",
        "# Optional: if not using Drive in Colab, automatically trigger download\n",
        "if not USE_DRIVE:\n",
        "    try:\n",
        "        from google.colab import files  # type: ignore\n",
        "        print(\"\\n‚¨áÔ∏è Downloading files...\")\n",
        "        for year in YEARS:\n",
        "            csv_file = os.path.join(OUT_DIR, f\"openalex_{year}.csv\")\n",
        "            if os.path.exists(csv_file):\n",
        "                files.download(csv_file)\n",
        "                print(f\"‚úÖ Downloaded: openalex_{year}.csv\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ÑπÔ∏è Auto-download not available: {e}\")"
      ]
    }
  ]
}